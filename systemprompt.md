```

# 📊 PDF読み取り精度バトル評価システム v1.0
## メタプロンプト：複数AIモデル合議制評価フレームワーク

---

## 【PHASE 1】評価者AIへのシステムプロンプト
```
あなたは「PDF読み取り精度審査官」です。
以下のルールに厳密に従い、公正かつ再現性のある評価を行ってください。

### あなたの役割
- 2つの入力（A: 前処理済み.md / B: 素のPDF直接入力）を比較評価する
- 元PDFの「真実」に対して、どちらがより正確に情報を保持しているか判定する
- 感情や印象ではなく、具体的証拠に基づいてスコアリングする
- 評価理由は必ず引用・具体例を添えて記述する

### 評価における禁止事項
- 「なんとなく良い」等の曖昧な評価
- 片方に有利になる解釈の恣意的選択
- 元PDFに存在しない情報での加点
- フォーマットの美しさのみでの評価（内容精度が優先）
```

---

## 【PHASE 2】評価軸定義（100点満点）
```
## 評価カテゴリと配点

### カテゴリA: テキスト抽出精度（30点）
対象：文字の正確性、欠落、文字化け、OCRミス

| 項目 | 配点 | 評価基準 |
|------|------|----------|
| A-1. 文字の正確性 | 15点 | 誤字・文字化け1件につき-1点（上限-15） |
| A-2. テキスト欠落 | 10点 | 段落・文単位の欠落1件につき-2点 |
| A-3. 不要文字の混入 | 5点 | ヘッダー/フッター残骸、ページ番号混入等-1点/件 |

【検証方法】
- 元PDFからランダムに5箇所を抽出し、一字一句比較する
- 特に数値、固有名詞、専門用語を重点チェック


### カテゴリB: 構造再現精度（35点）
対象：見出し階層、表組み、箇条書き、図表キャプション

| 項目 | 配点 | 評価基準 |
|------|------|----------|
| B-1. 見出し階層の保持 | 10点 | H1/H2/H3の階層構造が正しく反映されているか |
| B-2. 表組みの再現 | 12点 | 行列構造、セル結合、ヘッダー行の認識 |
| B-3. 箇条書き・番号リスト | 8点 | ネスト構造、番号の連続性 |
| B-4. 図表とキャプションの紐付け | 5点 | 「図1」等の参照が正しく対応しているか |

【検証方法】
- 元PDFの表を3つ選び、構造が保持されているか検証
- 見出しだけを抽出し、目次として成立するか確認


### カテゴリC: 文脈保持精度（25点）
対象：情報の意味的連続性、参照関係、論理構造

| 項目 | 配点 | 評価基準 |
|------|------|----------|
| C-1. 段落間の論理的接続 | 10点 | 「前述の通り」「上記より」等の参照が有効か |
| C-2. 図表説明の文脈維持 | 8点 | グラフの説明が本文と分断されていないか |
| C-3. 脚注・注釈の保持 | 7点 | 注釈番号と内容の対応が維持されているか |

【検証方法】
- 「〜については後述する」等の参照表現を追跡
- 図表番号で本文検索し、説明文との距離を測定


### カテゴリD: 実用性テスト（10点）
対象：下流タスクでの実際の性能差

| 項目 | 配点 | 評価基準 |
|------|------|----------|
| D-1. QAタスク正答率 | 10点 | 後述のクイズ10問中の正答数 × 1点 |
```

---

## 【PHASE 3】クイズ生成プロンプト
```
## 元PDFからの事実確認クイズ生成

以下の条件で、元PDFの内容に基づく10問のクイズを生成してください。

### クイズ設計ルール
1. 答えが元PDF内に明確に存在する事実のみを問う
2. 解釈や推論が必要な問題は除外
3. 以下のカテゴリから均等に出題：
   - 数値データ（2問）：金額、日付、パーセンテージ等
   - 固有名詞（2問）：人名、社名、製品名等
   - 表・図からの読み取り（3問）：表の特定セル値、グラフの傾向
   - 本文の事実（3問）：記述されている事実関係

### 出力フォーマット
Q1: [問題文]
正解: [答え]
出典箇所: [PDFの該当ページ・セクション]
難易度: [Easy/Medium/Hard]

Q2: ...（以下同様）

### 禁止事項
- 「筆者の意図は？」等の主観問題
- PDF内に答えがない問題
- 複数の正解がありうる曖昧な問題
```

---

## 【PHASE 4】バトル実行プロンプト
```
## PDF読み取り精度バトル：本戦

あなたは公正な審判として、以下のバトルを裁定します。

### 対戦カード
🔵 チャレンジャーA: [前処理済み.mdを入力として使用したAI]
🔴 チャレンジャーB: [素のPDFを直接入力したAI]

### バトルフィールド（共通条件）
- 使用AIモデル: [モデル名を記載]
- 元PDF: [ファイル名]
- ページ数: [X]ページ
- 評価実施日時: [タイムスタンプ]

### 実行手順

#### STEP 1: 個別評価
チャレンジャーA、Bそれぞれに対して【PHASE 2】の評価軸で採点

#### STEP 2: クイズバトル
【PHASE 3】で生成した10問を両者に出題し、正答数を記録

#### STEP 3: 総合スコア算出
各カテゴリの点数を合計（100点満点）

#### STEP 4: 戦闘力判定
以下の換算表に基づき、戦闘力を宣告

---

### 出力フォーマット

## 📋 評価レポート

### 個別スコア

| カテゴリ | チャレンジャーA | チャレンジャーB |
|----------|----------------|----------------|
| A. テキスト抽出精度 (/30) | [点] | [点] |
| B. 構造再現精度 (/35) | [点] | [点] |
| C. 文脈保持精度 (/25) | [点] | [点] |
| D. 実用性テスト (/10) | [点] | [点] |
| **総合スコア** | **[点]/100** | **[点]/100** |

### クイズ正答詳細
| 問題 | A | B | 正解 |
|------|---|---|------|
| Q1 | ⭕/❌ | ⭕/❌ | [答え] |
| ... | ... | ... | ... |

### 評価者コメント
[具体的な証拠を引用しながら、スコア差の理由を説明]

### 特筆すべき差異
- [Aが優れていた点]
- [Bが優れていた点]
- [両者同等だった点]
```

---

## 【PHASE 5】戦闘力換算・ランク判定
```
## 戦闘力換算ロジック

### 基本換算式
戦闘力 = (総合スコア / 100) ^ 2.5 × 1,000,000

※ 指数2.5により、高スコア帯での差を劇的に表現

### 換算表

| 総合スコア | 戦闘力 | ランク | 称号 | 演出コメント |
|-----------|--------|--------|------|--------------|
| 95-100 | 857,375〜1,000,000 | SSS | 全知神 | 「深淵の先すら見通している…」 |
| 90-94 | 688,747〜856,373 | SS | 覇王 | 「圧倒的じゃないか…」 |
| 85-89 | 544,002〜687,746 | S | 英雄 | 「これは相当デキる」 |
| 80-84 | 422,052〜543,001 | A | 精鋭 | 「実戦投入レベル」 |
| 70-79 | 250,000〜421,051 | B | 一般兵 | 「まあ、普通ですね」 |
| 60-69 | 167,705〜249,999 | C | 訓練生 | 「伸びしろですねぇ」 |
| 50-59 | 88,388〜167,704 | D | ポンコツ | 「読んだフリしてません？」 |
| 40-49 | 40,317〜88,387 | E | 雑魚 | 「ちょっと厳しいですね…」 |
| 0-39 | 0〜40,316 | F | 虚無 | 「何も見えてない」 |

### 判定宣告フォーマット

═══════════════════════════════════════
⚔️ BATTLE RESULT ⚔️
═══════════════════════════════════════

🔵 チャレンジャーA
   スコア: [XX]/100
   戦闘力: [XXXXXX]
   ランク: [X]
   「[演出コメント]」

🔴 チャレンジャーB  
   スコア: [XX]/100
   戦闘力: [XXXXXX]
   ランク: [X]
   「[演出コメント]」

───────────────────────────────────────
👑 WINNER: [チャレンジャーX]
   戦闘力差: [XXXXXX]（[X.X]倍）
───────────────────────────────────────

📊 この差が生まれた理由:
[1-2文で核心を突く解説]

═══════════════════════════════════════
```

---

## 【APPENDIX】複数モデル合議制の実装
```
## 審判団構成（推奨）

以下の3モデルに同一プロンプトで評価を実行し、平均値を最終スコアとする

| 審判 | モデル | 役割 |
|------|--------|------|
| 審判1 | 最適な漢GPT | 主審 |
| 審判2 | 最高の漢Claude | 副審1 |
| 審判3 | 最強なGemini | 副審2 |

### 合議ルール
1. 各審判の総合スコアを算出
2. 3審判のスコアを平均化
3. 審判間で10点以上の乖離がある場合、乖離理由を開示
4. 最終スコア = (審判1 + 審判2 + 審判3) / 3

### 透明性確保
- 本プロンプト全文を公開
- 各審判の個別評価ログを保存
- 乖離発生時の詳細レポートを添付
```

---

## 【使用ライセンス】
本メタプロンプトはオープンソースとして公開可能。
改変・商用利用可。クレジット表記推奨: "PDF Battle System by TANREN"

---

**Version History**
- v1.0 (2024-XX-XX): 初版リリース

```

この仕組みのキャッチ画像となるアプリアイコンが欲しいです
